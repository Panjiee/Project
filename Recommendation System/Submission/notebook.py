# -*- coding: utf-8 -*-
"""notebook.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gufmy8txzl8imAYVwhQgRzle4rQFuF58

# Laporan Proyek Machine Learning - Rosyd Panjie Laras

## Project Overview

Dalam era digital saat ini, pembelajaran online telah menjadi bagian penting dari pendidikan dan pengembangan pribadi. Platform pembelajaran online, seperti Coursera, telah memberikan akses luas kepada ribuan kursus dari berbagai bidang dan disajikan dengan cara yang mudah diakses oleh pengguna. Namun, keberagaman besar kursus yang tersedia sering kali menjadi tantangan bagi pengguna dalam menemukan kursus yang paling sesuai dengan minat, kebutuhan, dan tujuan belajar mereka.

Proyek ini bertujuan untuk mengatasi tantangan tersebut dengan mengembangkan sebuah sistem rekomendasi yang cerdas dan efektif menggunakan metode content-based filtering. Dengan menggunakan pendekatan ini, proyek ini akan membantu pengguna Coursera dalam menavigasi melalui kerumitan pilihan kursus dan memberikan rekomendasi yang personal dan relevan berdasarkan analisis konten kursus.

## Business Understanding

### Problem Statements
- Bagaimana cara mengembangkan sistem rekomendasi yang dapat merekomendasikan kursus-kursus yang relevan dengan preferensi pengguna di Coursera?

### Goals
Mengembangkan sistem rekomendasi menggunakan pendekatan content-based filtering untuk memberikan rekomendasi kursus yang paling sesuai dengan minat dan kebutuhan belajar pengguna. Dengan model ini, diharapkan pengguna Coursera dapat lebih efisien dalam menemukan kursus-kursus yang relevan dengan minat mereka, mengoptimalkan waktu belajar, dan mencapai tujuan pembelajaran dengan lebih baik.

### Solution Approach
Solusi yang diajukan dalam proyek ini mencakup langkah-langkah berikut:

- Pengumpulan dan Pembersihan Data: Langkah pertama adalah mengumpulkan dataset yang berisi informasi tentang kursus-kursus di platform Coursera, termasuk atribut-atribut seperti nama kursus, deskripsi, keterampilan yang diajarkan, dan tingkat kesulitan. Setelah itu, kami akan melakukan pembersihan data dengan mengatasi nilai yang hilang atau duplikat yang mungkin memengaruhi kualitas rekomendasi.

- Teknik Preprocessing: Preprocessing dilakukan untuk memastikan data siap digunakan dalam melatih dan menguji model. Langkah-langkah dalam tahapan ini meliputi:
    1. Menghapus duplikat pada kolom 'Course Name'
    2. Menghapus nilai 'Not Calibrated'
    3. Mengubah tipe data 'Course Rating' menjadi float
    4. Menghapus nilai 'Course Rating' yang kurang dari 4
    5. Menggabungkan nilai dari kolom 'Course Description', 'Skills', dan 'Difficulty Level',
    6. Menghapus tanda baca, tanda kurung, dan karakter khusus lainnya.

- Pengembangan model rekomendasi: Model dikembangkan dengan menerapkan metode content-based filtering menggunakan pendekatan TF-IDF (Term Frequency-Inverse Document Frequency) untuk menganalisis konten kursus. Penghitungan kemiripan kosinus antara kursus dilakukan berdasarkan matriks TF-IDF.

### Import Libraries
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import re
import seaborn as sns
from sklearn.feature_extraction.text import TfidfVectorizer
from wordcloud import WordCloud

"""### Read Datasets"""

df = pd.read_csv('Coursera.csv')
df.head()

df.info()

"""Feature

- Course Name: Nama-nama kursus sebagai pengenal utama dan dasar rekomendasi.
- Course Description: Ringkasan isi dan tujuan kursus, relevan untuk minat serupa.
- Skills: Kemampuan yang ingin ditanamkan, relevan dengan minat pengguna.
- Difficulty Level: Tingkat kesulitan kursus, sesuai keahlian dan tujuan.
- University: Informasi penyelenggara kursus.
- Course URL: Tautan ke kursus di Coursera, tanpa signifikansi dalam rekomendasi.
"""

# Print the count of null values in each column
print("Null Value Counts:")
print(df.isnull().sum())

print(f"Dataset size: {df.shape}")

# Calculate the sum of duplicated values in the 'Course Name' column
duplicates_count = df['Course Name'].duplicated().sum()

# Print the count of duplicated values
print("Jumlah duplikat pada kolom Course Name:", duplicates_count)

# Find and print duplicate rows based on 'Course Name'
duplicated_rows = df[df['Course Name'].duplicated(keep=False)]
duplicated_rows

df['Difficulty Level'].value_counts()

# Get value counts of the 'Difficulty Level' column
difficulty_counts = df['Difficulty Level'].value_counts()

# Set Seaborn style and color palette
sns.set_palette("viridis")

# Create a bar plot using Seaborn
plt.figure(figsize=(8, 6))
sns.barplot(x=difficulty_counts.index, y=difficulty_counts.values)
plt.title('Course Difficulty Level Distribution')
plt.xlabel('Difficulty Level')
plt.ylabel('Count')
plt.xticks(rotation=45)
plt.tight_layout()

# Show the plot
plt.show()

"""Data menunjukkan bahwa terdapat 1444 kursus dengan tingkat kesulitan "Beginner", yang menandakan adanya fokus pada memudahkan pemula untuk memulai belajar hal baru di platform Coursera."""

# Combine all skills into a single string
all_skills = ' '.join(df['Skills'])

# Create a WordCloud object
wordcloud = WordCloud(width=800, height=400, background_color='white').generate(all_skills)

# Display the word cloud using matplotlib
plt.figure(figsize=(10, 5))
plt.imshow(wordcloud, interpolation='bilinear')
plt.title('Skills Word Cloud')
plt.axis('off')  # Turn off axis
plt.tight_layout()

# Show the plot
plt.show()

from collections import Counter
# Get the word frequencies from the word cloud
word_freq = wordcloud.words_

# Print the top 5 most frequent words
top_words = Counter(word_freq).most_common(5)
for word, freq in top_words:
    print(f"'{word}'")

"""Word cloud menunjukkan lima kata yang paling sering muncul dalam deskripsi kursus: 'Management', 'Computer Science', 'Data Science', 'Machine Learning', dan 'Analysis'. Kata-kata ini mencerminkan tema utama dan fokus kursus-kursus dalam dataset, dengan penekanan pada bisnis, teknologi, data, dan analitik.

### Data Preprocessing
"""

# Drop duplicates on Course Name
df = df.drop_duplicates(subset='Course Name', keep='first')

# Remove values 'Not Calibrated'
df = df[df['Course Rating'] != 'Not Calibrated']

# Change dtypes of Course Rating to Float
df['Course Rating'] = df['Course Rating'].astype(float)

"""Langkah ini bertujuan agar sistem lebih mudah mengenali kursus yang relevan, yaitu kursus dengan rating di atas 4.5."""

# Combine values from 'Course Description', 'Skills', and 'Difficulty Level'
df['Combined'] = df['Course Description'] + ' ' + df['Skills'] + ' ' + df['Difficulty Level']

# Remove punctuation marks, parentheses, and other special characters
df['Combined'] = df['Combined'].apply(lambda x: re.sub(r'[^\w\s]', '', x))
df.head()

"""Teks dari "Course Description", "Skills", dan "Difficulty Level" digabungkan menjadi satu untuk memberikan informasi lengkap tentang kursus. Ini memungkinkan model memahami karakteristik kursus dengan lebih baik menggunakan pendekatan TF-IDF, menghasilkan representasi vektor yang lebih akurat.

### Model with Content Based Filtering
"""

from sklearn.feature_extraction.text import TfidfVectorizer

# Create a TfidfVectorizer
tf = TfidfVectorizer()

# Fit and transform the vectorizer on the combined text data
tfidf_matrix = tf.fit_transform(df['Combined'])

# Get feature names
feature_names = tf.get_feature_names_out()

# Print the shape of the TF-IDF matrix
print("TF-IDF Matrix Shape:", tfidf_matrix.shape)

# Print the dense representation of the TF-IDF matrix
print(tfidf_matrix.todense())

from sklearn.metrics.pairwise import cosine_similarity

# Calculate cosine similarity on matrix tf-idf
cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim.shape

def recommend(course, cosine_sim=cosine_sim, n=10):
    # Find the index of the given course in the DataFrame
    course_index = df[df['Course Name'] == course].index[0]

    # Calculate similarity scores between the given course and all other courses
    similar_courses = list(enumerate(cosine_sim[course_index]))

    # Sort the similar courses by similarity score in descending order
    similar_courses = sorted(similar_courses, key=lambda x: x[1], reverse=True)

    recommended_courses = []
    for index, score in similar_courses[:n]:
        rec_course = df.iloc[index]['Course Name']
        rec_score = df.iloc[index]['Course Rating']  # Tambah ini untuk mendapatkan nilai Course Rating
        recommended_courses.append((rec_course, rec_score, score))

    return recommended_courses

recommended_courses = recommend('Retrieve Data using Single-Table SQL Queries')

print(f"Top {len(recommended_courses)} Recommended Courses for 'Retrieve Data using Single-Table SQL Queries':")
for course, rating, score in recommended_courses:
    print(f"Recommended: {course}, Course Rating: {rating}, Similarity Score: {score:.2f}")

"""## Evaluation

Pada tahap evaluasi ini, metrik presisi dan recall digunakan untuk mengukur performa model sistem rekomendasi berbasis konten yang telah dibuat. Kursus-kursus yang direkomendasikan dengan skor kemiripan di atas 4.5 dianggap "relevant" berdasarkan rating tinggi. Dengan menghitung jumlah kursus "relevant" dan kursus yang direkomendasikan yang juga "relevant", presisi dan recall dapat dihitung.
"""

df['Course Rating'].describe()

actual_relevant = [course for course, rating, _ in recommended_courses if rating > 4.5]
relevant_count = len(actual_relevant)
relevant_in_recommendations = [course for course, rating, score in recommended_courses if course in actual_relevant]

if len(recommended_courses) > 0:
    precision = len(relevant_in_recommendations) / len(recommended_courses)
    recall = len(relevant_in_recommendations) / relevant_count
else:
    precision = 0
    recall = 0

print("Precision:", precision)
print("Recall:", recall)